{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5047f1aea1a4a4",
   "metadata": {},
   "source": [
    "# AIMS.au Statement Text Extraction Quality Analysis\n",
    "\n",
    "This notebook shows how to parse statement text that has already been extracted by using [ABBYY\n",
    "FineReader](https://pdf.abbyy.com/) and [PyMuPDF (fitz)](https://pymupdf.readthedocs.io/en/latest/).\n",
    "We also look into the main differences between these two sources of text.\n",
    "\n",
    "This notebook was last updated on 2024-04-19 for framework v0.5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5487af49a93eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import qut01\n",
    "\n",
    "qut01.utils.logging.setup_logging_for_analysis_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8b149751663e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_types = [\"fitz\", \"abbyy\"]\n",
    "\n",
    "parsers = {\n",
    "    parser_type: qut01.data.dataset_parser.DataParser(\n",
    "        dataset_path_or_object=qut01.data.dataset_parser.get_default_deeplake_dataset_path(),\n",
    "        dataset_branch=qut01.data.dataset_parser.dataset_annotated_branch_name,\n",
    "        add_processed_data_to_batch=True,\n",
    "        use_processed_data_cache=False,\n",
    "        sentence_source_text_tensor=f\"{parser_type}/text\",\n",
    "    )\n",
    "    for parser_type in parser_types\n",
    "}\n",
    "assert len(parsers[\"abbyy\"]) == len(parsers[\"fitz\"])\n",
    "statement_count = len(parsers[\"abbyy\"])\n",
    "print(f\"ready to analyze processed text for {statement_count} statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f76161cbf4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_lens, extracted_sentences, matched_sentences = {}, {}, {}\n",
    "MatchInfo = collections.namedtuple(\"MatchInfo\", [\"text\", \"score\"])  # noqa\n",
    "statement_idxs = list(range(statement_count))\n",
    "for parser_type in parser_types:\n",
    "    raw_text_lens[parser_type] = {}\n",
    "    extracted_sentences[parser_type] = {}\n",
    "    matched_sentences[parser_type] = {}\n",
    "    for statement_idx in tqdm.tqdm(statement_idxs, desc=f\"parsing {parser_type} data\"):\n",
    "        statement_id = parsers[parser_type].statement_ids[statement_idx]\n",
    "        statement_data = parsers[parser_type].get_processed_data(statement_idx)\n",
    "        raw_text_lens[parser_type][statement_id] = len(statement_data.text)\n",
    "        extracted_sentences[parser_type][statement_id] = statement_data.sentences\n",
    "        curr_matched_sentences = [list() for _ in statement_data.sentences]\n",
    "        for chunk in statement_data.annotation_chunks:\n",
    "            for chunk_sentence_idx in range(len(chunk.sentences)):\n",
    "                orig_sentence_idx = chunk.matched_sentences_orig_idxs[chunk_sentence_idx]\n",
    "                curr_matched_sentences[orig_sentence_idx].append(\n",
    "                    MatchInfo(\n",
    "                        text=chunk.sentences[chunk_sentence_idx],\n",
    "                        score=chunk.matched_sentences_scores[chunk_sentence_idx],\n",
    "                    )\n",
    "                )\n",
    "        matched_sentences[parser_type][statement_id] = curr_matched_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389ab1ffcd163d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(\n",
    "    ax,\n",
    "    abbyy_val,\n",
    "    fitz_val,\n",
    "    val_type_str,\n",
    "    float_val=False,\n",
    "):\n",
    "    rects = ax.bar(\n",
    "        [0, 1],\n",
    "        [abbyy_val, fitz_val],\n",
    "        0.8,\n",
    "        color=[\"red\", \"blue\"],\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(val_type_str)\n",
    "    ax.set_title(f\"Average {val_type_str} by Extraction Approach\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([\"abbyy\", \"fitz\"])\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(\n",
    "                f\"{height:.2f}\" if float_val else f\"{int(round(height))}\",\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "    autolabel(rects)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))  # noqa\n",
    "\n",
    "raw_text_lens_abbyy = list(raw_text_lens[\"abbyy\"].values())\n",
    "raw_text_lens_fitz = list(raw_text_lens[\"fitz\"].values())\n",
    "assert len(raw_text_lens_abbyy) == len(raw_text_lens_fitz)\n",
    "avg_text_len_abbyy = np.mean(raw_text_lens_abbyy)\n",
    "avg_text_len_fitz = np.mean(raw_text_lens_fitz)\n",
    "std_text_len_abbyy = np.std(raw_text_lens_abbyy)\n",
    "std_text_len_fitz = np.std(raw_text_lens_fitz)\n",
    "print(f\"abbyy text len mean={int(avg_text_len_abbyy)}, std={int(std_text_len_abbyy)}\")\n",
    "print(f\"fitz text len mean={int(avg_text_len_fitz)}, std={int(std_text_len_fitz)}\")\n",
    "plot_bars(\n",
    "    ax=ax[0, 0],\n",
    "    abbyy_val=avg_text_len_abbyy,\n",
    "    fitz_val=avg_text_len_fitz,\n",
    "    val_type_str=\"PDF Text Length\",\n",
    ")\n",
    "\n",
    "raw_seq_count_abbyy = [len(sentences) for sentences in extracted_sentences[\"abbyy\"].values()]\n",
    "raw_seq_count_fitz = [len(sentences) for sentences in extracted_sentences[\"fitz\"].values()]\n",
    "avg_seq_count_abbyy = np.mean(raw_seq_count_abbyy)\n",
    "avg_seq_count_fitz = np.mean(raw_seq_count_fitz)\n",
    "std_seq_count_abbyy = np.std(raw_seq_count_abbyy)\n",
    "std_seq_count_fitz = np.std(raw_seq_count_fitz)\n",
    "print(f\"abbyy seq count mean={int(avg_seq_count_abbyy)}, std={int(std_seq_count_abbyy)}\")\n",
    "print(f\"fitz seq count mean={int(avg_seq_count_fitz)}, std={int(std_seq_count_fitz)}\")\n",
    "plot_bars(\n",
    "    ax=ax[0, 1],\n",
    "    abbyy_val=avg_seq_count_abbyy,\n",
    "    fitz_val=avg_seq_count_fitz,\n",
    "    val_type_str=\"Sentence Count\",\n",
    ")\n",
    "\n",
    "raw_seq_lens_abbyy = [len(s) for sentences in extracted_sentences[\"abbyy\"].values() for s in sentences]\n",
    "raw_seq_lens_fitz = [len(s) for sentences in extracted_sentences[\"fitz\"].values() for s in sentences]\n",
    "avg_seq_lens_abbyy = np.mean(raw_seq_lens_abbyy)\n",
    "avg_seq_lens_fitz = np.mean(raw_seq_lens_fitz)\n",
    "std_seq_lens_abbyy = np.std(raw_seq_lens_abbyy)\n",
    "std_seq_lens_fitz = np.std(raw_seq_lens_fitz)\n",
    "print(f\"abbyy seq len mean={int(avg_seq_lens_abbyy)}, std={int(std_seq_lens_abbyy)}\")\n",
    "print(f\"fitz seq len mean={int(avg_seq_lens_fitz)}, std={int(std_seq_lens_fitz)}\")\n",
    "plot_bars(\n",
    "    ax=ax[1, 0],\n",
    "    abbyy_val=avg_seq_lens_abbyy,\n",
    "    fitz_val=avg_seq_lens_fitz,\n",
    "    val_type_str=\"Sentence Length\",\n",
    ")\n",
    "\n",
    "raw_scores_abbyy = [m.score for s in matched_sentences[\"abbyy\"].values() for matches in s if matches for m in matches]\n",
    "raw_scores_fitz = [m.score for s in matched_sentences[\"fitz\"].values() for matches in s if matches for m in matches]\n",
    "avg_scores_abbyy = np.mean(raw_scores_abbyy)\n",
    "avg_scores_fitz = np.mean(raw_scores_fitz)\n",
    "std_scores_abbyy = np.std(raw_scores_abbyy)\n",
    "std_scores_fitz = np.std(raw_scores_fitz)\n",
    "print(f\"abbyy scores mean={int(avg_scores_abbyy)}, std={int(std_scores_abbyy)}\")\n",
    "print(f\"fitz scores mean={int(avg_scores_fitz)}, std={int(std_scores_fitz)}\")\n",
    "plot_bars(\n",
    "    ax=ax[1, 1],\n",
    "    abbyy_val=avg_scores_abbyy,\n",
    "    fitz_val=avg_scores_fitz,\n",
    "    val_type_str=\"Match Score\",\n",
    "    float_val=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"analysis_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733fac448129f05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
