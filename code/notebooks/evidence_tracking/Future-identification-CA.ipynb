{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893c317e-3812-4c83-b3b4-b133426eef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import math\n",
    "future = pd.read_csv(\"./data/ca_futre_labels.csv\", header=None).iloc[:,0].to_list()\n",
    "not_done = pd.read_csv(\"./data/ca_future.csv\" , encoding=\"latin1\").dropna(how='all').sentence_id.astype(int)\n",
    "\n",
    "\n",
    "idx = pd.read_csv(\"./data/ca_future.csv\", encoding=\"latin1\").dropna(how='all').sentence_id.astype(int)\n",
    "# for ground-truth .targets, for model results, .predictions\n",
    "labels = pd.read_csv(\"./data/ca_future.csv\", encoding=\"latin1\").dropna(how='all').predictions\n",
    "sentences = pd.read_csv(\"./data/ca_future.csv\", encoding=\"latin1\").dropna(how='all').sentence_text\n",
    "labels = [ast.literal_eval(str(i)) if not isinstance(i, float) or not math.isnan(i) else [0 for ii in range(11)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a92c8b1-f790-4603-99d8-c70e86c62d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_future_labels = []\n",
    "for sentence, data, i in zip(sentences, np.array(labels), idx):\n",
    "    for ii, lbs in enumerate(data[3:]):\n",
    "        if lbs == 1:\n",
    "            if i in future:\n",
    "                task_future_labels.append(1)\n",
    "            else:\n",
    "                task_future_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a58e097-3c13-4ba7-bdb3-71842e8f7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name = [\n",
    "    \"approval\",\n",
    "    \"signature\",\n",
    "    \"c1 (reporting entity)\",\n",
    "    \"c2 (structure)\",\n",
    "    \"c2 (operations)\",\n",
    "    \"c2 (supply chains)\",\n",
    "    \"c3 (risk description)\",\n",
    "    \"c4 (risk mitigation)\",\n",
    "    \"c4 (remediation)\",\n",
    "    \"c5 (effectiveness)\",\n",
    "    \"c6 (consultation)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1a0728-f43c-4027-8a37-676963b74b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/duoyizhang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/duoyizhang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure required NLTK models are downloaded\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "def identify_tense_nltk(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    tenses = {\"past\": 0, \"future\": 0}\n",
    "    is_future = False\n",
    "\n",
    "    # Expanded future-indicative words & phrases\n",
    "    # future_keywords = [\n",
    "    #     \"will\", \"intend\", \"expect\", \"aim\", \"plan\", \"anticipate\", \"future\",\n",
    "    #     \"going to\", \"shall\", \"may include\", \"plans to\", \"in 2024\", \"next year\",\n",
    "    #     \"at a later stage\", \"commit to\", \"schedule\", \"set to\", \"forecast\",\n",
    "    #     \"expected to\", \"proposed\", \"continue to\", \"implement\", \"develop\",\n",
    "    #     \"undertake\", \"consider\", \"establish\", \"introduce\", \"expand\",\n",
    "    #     \"launch\", \"explore\", \"assess\", \"enhance\", \"embed\", \"increase\",\n",
    "    #     \"next steps\", \"to be completed\"\n",
    "    # ]\n",
    "    future_keywords = [\n",
    "        \"will\", \"intend\", \"expect\", \"aim\", \"plan\", \"anticipate\", \"future\",\n",
    "        \"going to\", \"shall\", \"may include\", \"plans to\", \"2024\", \"next year\",\n",
    "        \"at a later stage\", \"next steps\", \"to be completed\", \"continue\",\"continuing\"\n",
    "    ]\n",
    "\n",
    "    # imperative_verbs = {\"insert\", \"implement\", \"embed\", \"incorporate\", \"continue\",\n",
    "    #                     \"recruit\", \"develop\", \"require\", \"ensure\", \"review\",\n",
    "    #                     \"provide\", \"publish\", \"categorize\", \"train\"}\n",
    "    imperative_verbs = {}\n",
    "\n",
    "    # Convert sentence to lowercase for easier keyword matching\n",
    "    sentence_lower = sentence.lower()\n",
    "\n",
    "    for i, (word, tag) in enumerate(tagged_words):\n",
    "        # # Count past tense verbs\n",
    "        # if tag == \"VBD\":\n",
    "        #     tenses[\"past\"] += 1\n",
    "        # Detect future modal verbs\n",
    "        if tag == \"MD\" and word.lower() in [\"will\", \"shall\"]:\n",
    "            tenses[\"future\"] += 1\n",
    "            is_future = True\n",
    "        # Identify infinitives that imply future actions (e.g., \"to implement\")\n",
    "        elif tag == \"TO\" and i + 1 < len(tagged_words) and tagged_words[i + 1][1] == \"VB\":\n",
    "            if tagged_words[i + 1][0].lower() in future_keywords:\n",
    "                tenses[\"future\"] += 1\n",
    "                is_future = True\n",
    "        if any(keyword in sentence_lower for keyword in future_keywords):\n",
    "            tenses[\"future\"] += 1\n",
    "            is_future = True\n",
    "\n",
    "    # Return \"future\" if future context was detected\n",
    "    if is_future:\n",
    "        return \"future\"\n",
    "\n",
    "    # Determine the dominant tense based on counts\n",
    "    #dominant_tense = max(tenses, key=tenses.get)\n",
    "    return \"no\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd98993-04cb-4a24-bfc7-4c3bf25d973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results = {key:[] for key in labels_name[3:]}\n",
    "predicted_results = []\n",
    "st = []\n",
    "for sentence, data in zip(sentences, np.array(labels)):\n",
    "    for idx, lbs in enumerate(data[3:]):\n",
    "        if lbs == 1:\n",
    "            result = identify_tense_nltk(sentence)\n",
    "            if result == 'future':\n",
    "                predicted_results.append(1)\n",
    "            else:\n",
    "                predicted_results.append(0)\n",
    "            st.append(sentence)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ed0269-dd8c-47ef-ac8d-130f65dd10e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy is  0.897513644633111\n"
     ]
    }
   ],
   "source": [
    "correct = sum(t == p for t, p in zip(task_future_labels, predicted_results))\n",
    "print(\"Overall accuracy is \", correct / len(task_future_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce158706-f395-4cbf-a301-515c07684e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on prediction future works:  0.84\n"
     ]
    }
   ],
   "source": [
    "pos = np.array(task_future_labels)==1\n",
    "correct = sum(t == p for t, p in zip(np.array(task_future_labels)[pos], np.array(predicted_results)[pos]))\n",
    "print(\"Accuracy on prediction future works: \", correct / len(np.array(task_future_labels)[pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f79e29a-bc7c-4b26-a59a-93acaff26827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897513644633111\n",
      "0.9339413425343102\n",
      "0.5721532124472447\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(task_future_labels, predicted_results, average='micro')) \n",
    "print(f1_score(task_future_labels, predicted_results, average='weighted'))\n",
    "print(f1_score(task_future_labels, predicted_results, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf70041-158e-44a3-9a00-0416be73e2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
