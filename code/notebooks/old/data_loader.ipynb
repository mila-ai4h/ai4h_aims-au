{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f95b11c07b3986",
   "metadata": {},
   "source": [
    "# Statement DataModule Analysis\n",
    "\n",
    "This notebook showcase how to prepare the train/valid/test partitions, as done for the paper submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b09a65015e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "\n",
    "import hydra\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import pandas\n",
    "import torch\n",
    "import torchmetrics\n",
    "import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "import qut01.utils.config\n",
    "import qut01.utils.logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = qut01.utils.logging.setup_logging_for_analysis_script()\n",
    "data_config_name = \"statement_sampler.yaml\"\n",
    "logger.info(f\"initializing hydra and fetching data config for '{data_config_name}'...\")\n",
    "overrides = [\n",
    "    f\"data={data_config_name}\",\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "]\n",
    "config = qut01.utils.config.init_hydra_and_compose_config(overrides=overrides)\n",
    "logger.info(\"initialization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041003af0a8a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Instantiating datamodule: {config.data.datamodule._target_}\")  # noqa\n",
    "datamodule: pl.LightningDataModule = hydra.utils.instantiate(config.data.datamodule)\n",
    "assert isinstance(datamodule, pl.LightningDataModule), f\"unexpected type: {type(datamodule)}\"\n",
    "logger.info(\"running 'datamodule.prepare_data()'...\")\n",
    "datamodule.prepare_data()\n",
    "logger.info(\"running 'datamodule.setup()'...\")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "logger.info(\"fetching train data loader...\")\n",
    "dataloader = datamodule.train_dataloader()\n",
    "logger.info(\"train data loader ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19505c99-b5d4-4b1f-8288-0a97913d3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "tot_count = 0\n",
    "max_amount = -1\n",
    "print_data = False\n",
    "\n",
    "try:\n",
    "    # for item in tqdm.tqdm(itertools.chain(datamodule.train_dataloader(), datamodule.val_dataloader(), datamodule.test_dataloader())):\n",
    "    for item in tqdm.tqdm(datamodule.val_dataloader()):\n",
    "        # comment above and uncommment the next depending on the partition to iterate on\n",
    "        # for item in tqdm.tqdm(datamodule.train_dataloader()):\n",
    "        # for item in tqdm.tqdm(datamodule.test_dataloader()):\n",
    "        for i, sentence_text in enumerate(item[\"sentence_orig_text\"]):\n",
    "            tot_count += 1\n",
    "            sentence_statement_id = int(item[\"statement_id\"][i])\n",
    "            sentence_orig_idxs = item[\"sentence_orig_idxs\"][i]\n",
    "            assert len(sentence_orig_idxs) == 1\n",
    "            sentence_orig_idxs = int(sentence_orig_idxs[0])\n",
    "            text_with_context = item[\"text\"][i]\n",
    "            target_classes = [int(x) for x in item[\"relevance\"][i, :]]\n",
    "            assert (\n",
    "                text_with_context == sentence_text\n",
    "            ), f\"context must be disabled in this experiment. Found '{text_with_context}'\"\n",
    "\n",
    "            if print_data:\n",
    "                print(f\"sentence text: {sentence_text}\")\n",
    "                print(f\"target classes: {target_classes}\")\n",
    "                print(\"\\n\")\n",
    "\n",
    "            if max_amount > -1 and tot_count >= max_amount:\n",
    "                break\n",
    "\n",
    "        if max_amount > -1 and tot_count >= max_amount:\n",
    "            break\n",
    "            print(f\"reached the max amount of {max_amount}\")\n",
    "finally:\n",
    "    print(f\"{tot_count} have been parsed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
