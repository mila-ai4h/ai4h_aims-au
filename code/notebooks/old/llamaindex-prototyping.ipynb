{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import lightning.pytorch as pl\n",
    "import llama_index.core.query_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import qut01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff0fe0e1b90445",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = qut01.utils.logging.setup_logging_for_analysis_script()\n",
    "data_config_name = \"statement_sampler.yaml\"\n",
    "logger.info(f\"initializing hydra and fetching data config for '{data_config_name}'...\")\n",
    "overrides = [\n",
    "    f\"data={data_config_name}\",\n",
    "    \"data.classif_setup=c2-c3-c4-c5-c6\",\n",
    "    \"data.num_criteria=8\",\n",
    "]\n",
    "config = qut01.utils.config.init_hydra_and_compose_config(overrides=overrides)\n",
    "logger.info(\"initialization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e38ff6d88352a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_and_background_str = (  # generic\n",
    "    \"You are an analyst that inspects modern slavery declarations made by Australian reporting entities. \"\n",
    "    \"You are specialized in the analysis of statements made with respect to the Australian Modern Slavery \"\n",
    "    \"Act of 2018, and not of any other legislation.\"\n",
    ")\n",
    "\n",
    "definitions_c2_sc_str = (  # c2-sc\n",
    "    # note: description below is summarized from the spec, which is largely based on the guidance doc\n",
    "    \"You are currently looking for sentences in statements that describe the SUPPLY CHAINS of an entity, \"\n",
    "    \"where supply chains refer to the sequences of processes involved in the procurement of products and \"\n",
    "    \"services (including labour) that contribute to the reporting entity's own products and services. The \"\n",
    "    \"description of a supply chain can be related, for example, to 1) the products that are provided by \"\n",
    "    \"suppliers; 2) the services provided by suppliers, or 3) the location, category, contractual \"\n",
    "    \"arrangement, or other attributes that describe the suppliers. Any sentence that contains these kinds \"\n",
    "    \"of information is considered relevant. Descriptions that apply to indirect suppliers (i.e. \"\n",
    "    \"suppliers-of-suppliers) are considered relevant. Descriptions of the supply chains of entities owned \"\n",
    "    \"or controlled by the reporting entity making the statement are also considered relevant. However, \"\n",
    "    \"descriptions of 'downstream' supply chains, i.e. of how customers and clients of the reporting \"\n",
    "    \"entity use its products or services, are NOT considered relevant. Finally, sentences that describe \"\n",
    "    \"how the reporting entity lacks information on some of its supply chain, or how some of its supply \"\n",
    "    \"chains are still unmapped or unidentified, are also considered relevant.\"\n",
    ")\n",
    "\n",
    "relevance_classif_descriptions_str = (  # @@@@@ note: this is for \"DESCRIPTIONS\", not actions\n",
    "    \"Given the above definitions of what constitutes a relevant sentence, you will need to determine if a \"\n",
    "    \"target sentence is relevant or not inside a larger block of text. The target sentence will first be \"\n",
    "    \"provided by itself so you can know which sentence we want to classify. It will then be provided again \"\n",
    "    \"as part of the larger block of text it originally came from (extracted from a PDF file) so you can \"\n",
    "    \"analyze it with more context. While some of the surrounding sentences may be relevant according to \"\n",
    "    \"the earlier definitions, we are only interested in classifying the target sentence according to the \"\n",
    "    \"relevance of its own content. You must avoid labeling sentences with only vague descriptions or \"\n",
    "    \"corporate talk (and no actual information) as relevant.\"\n",
    ")\n",
    "\n",
    "answer_formatting_str = (\n",
    "    \"The answer you provide regarding whether the sentence is relevant or not can only be 'YES' or 'NO', \"\n",
    "    \"and nothing else.\"\n",
    ")\n",
    "\n",
    "# examples_c2_sc_str = (\n",
    "#     \"todo\" @@@@@\n",
    "# )\n",
    "\n",
    "target_sentence_str = (\n",
    "    \"The target sentence to classify is the following:\" \"\\n------------\\n{target_sentence}\\n------------\"\n",
    ")\n",
    "\n",
    "sentence_with_context_str = (\n",
    "    \"The same target sentence inside its original block of text:\" \"\\n------------\\n{text}\\n------------\"\n",
    ")\n",
    "\n",
    "final_question_str = \"Is the target sentence relevant? (YES/NO)\"\n",
    "\n",
    "template_c2_sc_str = (\n",
    "    f\"{role_and_background_str}\\n\\n\"\n",
    "    f\"{definitions_c2_sc_str}\\n\\n\"\n",
    "    f\"{relevance_classif_descriptions_str}\\n\\n\"\n",
    "    f\"{answer_formatting_str}\\n\\n\"\n",
    "    # f\"{examples_c2_sc_str}\\n\\n\"\n",
    "    f\"{target_sentence_str}\\n\\n\"\n",
    "    f\"{sentence_with_context_str}\\n\\n\"\n",
    "    f\"{final_question_str}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96ffa8b0a66f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index.core\n",
    "import llama_index.core.query_pipeline\n",
    "import llama_index.llms.openai\n",
    "\n",
    "query_target_class = \"c2 (supply chains)\"\n",
    "\n",
    "print(f\"{query_target_class} prompt template preview:\\n\\n{template_c2_sc_str}\")\n",
    "prompt_c2_sc = llama_index.core.PromptTemplate(template_c2_sc_str)\n",
    "\n",
    "llm_gpt3 = llama_index.llms.openai.OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    # temperature: float = DEFAULT_TEMPERATURE,\n",
    "    # max_tokens: Optional[int] = None,\n",
    "    # additional_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    # max_retries: int = 3,\n",
    "    # timeout: float = 60.0,\n",
    "    # reuse_client: bool = True,\n",
    ")\n",
    "\n",
    "query_pipeline = llama_index.core.query_pipeline.QueryPipeline(\n",
    "    chain=[prompt_c2_sc, llm_gpt3],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaea7b98cd0e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Instantiating datamodule: {config.data.datamodule._target_}\")  # noqa\n",
    "datamodule: pl.LightningDataModule = hydra.utils.instantiate(config.data.datamodule)\n",
    "assert isinstance(datamodule, pl.LightningDataModule), f\"unexpected type: {type(datamodule)}\"\n",
    "logger.info(\"running 'datamodule.prepare_data()'...\")\n",
    "datamodule.prepare_data()\n",
    "logger.info(\"running 'datamodule.setup()'...\")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "target_subset_name = \"valid\"\n",
    "logger.info(f\"fetching {target_subset_name} data loader...\")\n",
    "dataloader_getter = getattr(datamodule, f\"{target_subset_name}_dataloader\")\n",
    "dataloader = dataloader_getter()\n",
    "logger.info(f\"{target_subset_name} data loader ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584cfbbc9052636",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_relevance_flag = 0\n",
    "while not target_relevance_flag > 0:\n",
    "    batch = next(iter(dataloader))\n",
    "    batch_size = batch[\"batch_size\"]\n",
    "    sample_idx = np.random.randint(batch_size)\n",
    "    sample_id = batch[\"batch_id\"][sample_idx]\n",
    "    target_sentence = batch[\"sentence_orig_text\"][sample_idx]\n",
    "    text = batch[\"text\"][sample_idx]\n",
    "    target_relevance_flag = batch[\"relevance\"][sample_idx][batch[\"class_names\"].index(query_target_class)].item()\n",
    "    print(f\"{sample_id=}\")\n",
    "    print(f\"{target_sentence=}\")\n",
    "    print(f\"{text=}\")\n",
    "    print(f\"{target_relevance_flag=}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f163e8d17f3c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_pipeline.run(target_sentence=target_sentence, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85459ebb0f0541e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c233ddfaffb69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "id": "4fd9b1c48efee006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
