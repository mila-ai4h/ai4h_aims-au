{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331c475e",
   "metadata": {},
   "source": [
    "# token analysis with and without context\n",
    "\n",
    "This notebook analyses the token count distribution for the various model families (BERT, Llama, ...), and with and without context. Also, it computes how many sentences are cut by specifying a determined max_token_count param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3430b-1a33-4b71-bb4e-0acfca398e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change cwd to import qut01\n",
    "# Q: Is therean easy way to set the working directory of the notebook at launch?\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1db902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import hydra\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import qut01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a802717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(config_overrides):\n",
    "    logger = qut01.utils.logging.setup_logging_for_analysis_script()\n",
    "    data_config_name = \"sentence_sampler.yaml\"\n",
    "    logger.info(f\"initializing hydra and fetching data config for '{data_config_name}'...\")\n",
    "\n",
    "    config = qut01.utils.config.init_hydra_and_compose_config(overrides=config_overrides)\n",
    "    logger.info(\"initialization complete!\")\n",
    "\n",
    "    logger.info(f\"Instantiating datamodule: {config.data.datamodule._target_}\")  # noqa\n",
    "    datamodule: pl.LightningDataModule = hydra.utils.instantiate(config.data.datamodule)\n",
    "    assert isinstance(datamodule, pl.LightningDataModule), f\"unexpected type: {type(datamodule)}\"\n",
    "    logger.info(\"running 'datamodule.prepare_data()'...\")\n",
    "    datamodule.prepare_data()\n",
    "    logger.info(\"running 'datamodule.setup()'...\")\n",
    "    datamodule.setup(stage=\"fit\")\n",
    "    return datamodule, datamodule.train_dataloader(), datamodule.val_dataloader(), datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_count(dataloader):\n",
    "    batch_eq_to_none = 0\n",
    "    token_id_counts = []\n",
    "\n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "        if batch is None:\n",
    "            batch_eq_to_none += 1\n",
    "            continue\n",
    "        batch_tokens = batch[\"sentence_token_ids\"]\n",
    "        assert batch_tokens.shape[0] == 1, \"\"\n",
    "        token_id_count = batch_tokens.shape[1]\n",
    "        token_id_counts.append(token_id_count)\n",
    "    print(f\"found {batch_eq_to_none} batches equal to None\")\n",
    "    return token_id_counts\n",
    "\n",
    "\n",
    "def plot_distributions(\n",
    "    tokens,\n",
    "    names,\n",
    "    bins=100,\n",
    "):\n",
    "    fig, axs = plt.subplots(nrows=len(tokens) * 2, figsize=[10, 16])\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        # Histogram\n",
    "        ax = axs[2 * i]\n",
    "        ax.hist(tokens[i], bins=bins)\n",
    "        ax.set_title(f\"Histogram of token counts for {name}\")\n",
    "        ax.set_xlabel(\"Token count\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.grid(axis=\"y\", alpha=0.75)\n",
    "        ax.yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "\n",
    "        # CDF\n",
    "        ax = axs[2 * i + 1]\n",
    "        ax.hist(tokens[i], bins=bins, cumulative=-1, density=True)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_ylim(1e-4, 1)\n",
    "        ax.set_title(f\"CDF of token counts for {name}\")\n",
    "        ax.set_xlabel(\"Token count\")\n",
    "        ax.set_ylabel(\"% samples with greater than x tokens\")\n",
    "        ax.grid(True, which=\"major\", alpha=0.75)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_percentage_of_samples_above_length(tokens, length_threshold) -> float:\n",
    "    return 100 * sum([x >= length_threshold for x in tokens]) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9a005-b92f-4b5d-86bd-a3537714b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_token_counts(config_overrides):\n",
    "    # Grab the dataloaders for the specified config\n",
    "    datamodule, train_dl, valid_dl, test_dl = get_dataloaders(config_overrides)\n",
    "\n",
    "    # Print the used vocabulary, to make sure we are dealing with the exepected one\n",
    "    example = next(iter(train_dl))\n",
    "    print()\n",
    "    print(\"*** TESTING TOKENIZER WITH EXAMPLE ***\")\n",
    "    print(f\"sentence is:\\n{example['sentence_orig_text']}\")\n",
    "    print(f\"token ids are:\\n{example['sentence_token_ids']}\")\n",
    "\n",
    "    train_tokens = get_token_count(train_dl)\n",
    "    val_tokens = get_token_count(valid_dl)\n",
    "    test_tokens = get_token_count(test_dl)\n",
    "\n",
    "    # Perform cutoff analysis\n",
    "    print()\n",
    "    print(\"*** CUTOFF ANALYSIS ***\")\n",
    "    for cutoff in range(0, 2000, 50):\n",
    "\n",
    "        print()\n",
    "        print(\"Cutoff = {} tokens\".format(cutoff))\n",
    "        for tokens, name in zip([train_tokens, val_tokens, test_tokens], [\"train\", \"valid\", \"test\"]):\n",
    "            # for tokens, name in zip([val_tokens, test_tokens], ['valid', 'test']):\n",
    "            print(\n",
    "                \"{} has {:.2f} % of samples over\".format(\n",
    "                    name,\n",
    "                    get_percentage_of_samples_above_length(tokens, cutoff),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Generate distribution plots\n",
    "    plot_distributions([train_tokens, val_tokens, test_tokens], [\"train\", \"valid\", \"test\"])\n",
    "    # plot_distributions([val_tokens, test_tokens], ['valid', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ff38f",
   "metadata": {},
   "source": [
    "# DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b17d98",
   "metadata": {},
   "source": [
    "## No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8058427",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=distilbert-base-uncased\",\n",
    "    \"data.context_word_count=0\",  # no context\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fb99d",
   "metadata": {},
   "source": [
    "## 300 Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daad005-e3cb-4481-9ab1-3fba3f40a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=distilbert-base-uncased\",\n",
    "    \"data.context_word_count=300\",\n",
    "    \"data.left_context_boundary_token='[SEP]'\",\n",
    "    \"data.right_context_boundary_token='[SEP]'\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722691da-732d-4532-b4ad-5526ad4ddd2b",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682e5d3-b362-4a58-bcdb-8d291cc58611",
   "metadata": {},
   "source": [
    "## No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a084e12-5020-4872-b6ee-6ea0f0d4bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=bert-base-uncased\",\n",
    "    \"data.context_word_count=0\",  # no context\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dac3b6-d62a-4ab3-80c6-93aa9b2c3377",
   "metadata": {},
   "source": [
    "## 100 Words Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a119d-a021-4588-bdde-1aef125c1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=bert-base-uncased\",\n",
    "    \"data.context_word_count=100\",\n",
    "    \"data.left_context_boundary_token='[SEP]'\",\n",
    "    \"data.right_context_boundary_token='[SEP]'\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e58bd21-0b84-4db7-a1d2-e2c15a008eef",
   "metadata": {},
   "source": [
    "## 200 Words Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ac612-0acd-4c28-8729-209a909ca09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=bert-base-uncased\",\n",
    "    \"data.context_word_count=200\",\n",
    "    \"data.left_context_boundary_token='[SEP]'\",\n",
    "    \"data.right_context_boundary_token='[SEP]'\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3c7e4-1c6a-47ff-9873-97c4243439fc",
   "metadata": {},
   "source": [
    "## 300 Words Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251df76-f472-4381-8e2a-fb4a9129bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=bert-base-uncased\",\n",
    "    \"data.context_word_count=300\",\n",
    "    \"data.left_context_boundary_token='[SEP]'\",\n",
    "    \"data.right_context_boundary_token='[SEP]'\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad6a59",
   "metadata": {},
   "source": [
    "# LLAMA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8091fa-3d74-4eca-90bd-21933743cb5a",
   "metadata": {},
   "source": [
    "## No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbf068-7987-4409-ac05-e00da2c82cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler_with_llama_tokenizer.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f21131-4673-4776-9773-246b9c056326",
   "metadata": {},
   "source": [
    "## 100 Words Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda902d-7363-4d6d-b1ff-ddbca132bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler_with_llama_tokenizer.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"data.context_word_count=100\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543e3cb-a9c3-42a4-b692-88978a9d34d0",
   "metadata": {},
   "source": [
    "## 200 Words Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c730e-6992-430b-92d7-1c6e6a2e0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler_with_llama_tokenizer.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"data.context_word_count=200\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee5075-6dbd-48ff-a76d-a2c42178b2c6",
   "metadata": {},
   "source": [
    "## 300 Words Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c26970-fb03-4a78-ac61-191ce2a9a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_overrides = [\n",
    "    'data=\"sentence_sampler_with_llama_tokenizer.yaml\"',\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"data.sentence_batch_size=1\",  # useful so that there is no padding around\n",
    "    \"data.context_word_count=300\",\n",
    "]\n",
    "analyze_token_counts(config_overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00aec9a-aa2f-4ebc-84dc-ec3641b949ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
