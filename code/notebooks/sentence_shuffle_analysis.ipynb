{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502398ab8abb158b",
   "metadata": {},
   "source": [
    "# AIMS.au Sentence DataModule Shuffle Analysis\n",
    "\n",
    "This notebook analyzes the data loaded by the sentence data module. For a more simple demo showing\n",
    "how to parse the statement dataset, see [this notebook](./data_parsing_demo.ipynb).\n",
    "\n",
    "This notebook was last updated on 2024-05-07 for framework v0.5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import hydra\n",
    "import lightning.pytorch as pl\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import qut01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d4ecca2dce0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = qut01.utils.logging.setup_logging_for_analysis_script()\n",
    "data_config_name = \"sentence_sampler.yaml\"\n",
    "logger.info(f\"initializing hydra and fetching data config for '{data_config_name}'...\")\n",
    "overrides = [\n",
    "    f\"data={data_config_name}\",\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "]\n",
    "config = qut01.utils.config.init_hydra_and_compose_config(overrides=overrides)\n",
    "logger.info(\"initialization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38930bcfe12c73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Instantiating datamodule: {config.data.datamodule._target_}\")  # noqa\n",
    "datamodule: pl.LightningDataModule = hydra.utils.instantiate(config.data.datamodule)\n",
    "assert isinstance(datamodule, pl.LightningDataModule), f\"unexpected type: {type(datamodule)}\"\n",
    "logger.info(\"running 'datamodule.prepare_data()'...\")\n",
    "datamodule.prepare_data()\n",
    "logger.info(\"running 'datamodule.setup()'...\")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "logger.info(\"fetching train data loader...\")\n",
    "dataloader = datamodule.train_dataloader()\n",
    "logger.info(\"train data loader ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449b55655e3c6e2",
   "metadata": {},
   "source": [
    "Note: we do the shuffle analysis in two stages, first for the \"beginning\" of the dataloader loop\n",
    "(where shuffling will likely be worse due to the buffer being filled), and for \"later\" in the loop\n",
    "(where the buffer should have been filled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795a949bf7a8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shuffle_stats(sentence_ids_: typing.List[str], prefix_str: str) -> None:\n",
    "    statement_ids = [sid.split(\":\")[0] for sid in sentence_ids_]\n",
    "    unique_statement_ids, unique_counts = np.unique(statement_ids, return_counts=True)\n",
    "    top_idx = np.argmax(unique_counts)\n",
    "    most_common_statement_id = statement_ids[top_idx]\n",
    "    unique_statement_ratio = len(unique_statement_ids) / len(sentence_ids_)\n",
    "    duplicated_sentence_count = len(sentence_ids_) - len(set(sentence_ids_))  # happens due to multiple annotations\n",
    "    duplicated_sentence_ratio = duplicated_sentence_count / len(sentence_ids_)\n",
    "    print(prefix_str)\n",
    "    print(f\"\\tunique statement count: {len(unique_statement_ids)} (higher is better)\")\n",
    "    print(f\"\\tunique statement ratio: {unique_statement_ratio:0.2%} (higher is better)\")\n",
    "    print(f\"\\tmost common statement: '{most_common_statement_id}' ({unique_counts[top_idx]} sentences)\")\n",
    "    print(f\"\\tduplicated sentence count: {duplicated_sentence_count} (lower is better)\")\n",
    "    print(f\"\\tduplicated sentence ratio: {duplicated_sentence_ratio:0.1%} (lower is better)\")\n",
    "\n",
    "\n",
    "min_sentence_count = 256  # should be the sentence count you expect to use as batch size to train your model\n",
    "\n",
    "sentence_ids = []\n",
    "for batch in tqdm.tqdm(dataloader, desc=\"sampling sentences\"):\n",
    "    assert \"batch_id\" in batch, \"need batch (sentence) identifiers for analysis\"\n",
    "    sentence_ids.extend([sid for sid in batch[\"batch_id\"]])\n",
    "    if len(sentence_ids) >= min_sentence_count:\n",
    "        break\n",
    "assert all([isinstance(sid, str) for sid in sentence_ids]), \"unexpected sentence id types (should all be strings?)\"\n",
    "assert all(\n",
    "    [sid.startswith(\"statement\") and \":sentence\" in sid for sid in sentence_ids]\n",
    "), \"unexpected sentence id string formatting (should be statementXXXXX:sentenceYYYYY\"\n",
    "print_shuffle_stats(\n",
    "    sentence_ids_=sentence_ids,\n",
    "    prefix_str=f\"SHUFFLE STATS FOR THE FIRST {len(sentence_ids)} SENTENCES:\",\n",
    ")\n",
    "\n",
    "skip_sentence_count = 100000  # we'll skip over these, and re-evaluate shuffling afterwards\n",
    "skipped_sentence_count = 0\n",
    "sentence_ids = []\n",
    "for batch in tqdm.tqdm(dataloader, desc=\"resampling new sentences\"):\n",
    "    assert \"batch_id\" in batch, \"need batch (sentence) identifiers for analysis\"\n",
    "    if skipped_sentence_count < skip_sentence_count:\n",
    "        skipped_sentence_count += len(batch[\"batch_id\"])\n",
    "        continue\n",
    "    sentence_ids.extend([sid for sid in batch[\"batch_id\"]])\n",
    "    if len(sentence_ids) >= min_sentence_count:\n",
    "        break\n",
    "print_shuffle_stats(\n",
    "    sentence_ids_=sentence_ids,\n",
    "    prefix_str=f\"SHUFFLE STATS FOR {len(sentence_ids)} SENTENCES AFTER SKIPPING {skipped_sentence_count}:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b68e8b8e04032d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
