{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import qut01\n",
    "\n",
    "qut01.utils.logging.setup_logging_for_analysis_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b78bb217cbb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = qut01.data.dataset_parser.get_default_deeplake_dataset_path()\n",
    "dataset = qut01.data.dataset_parser.get_deeplake_dataset(  # this will load the deeplake dataset itself\n",
    "    dataset_path=dataset_path,\n",
    "    checkout_branch=qut01.data.dataset_parser.dataset_validated_branch_name,  # to load all annotations (train-valid-test)\n",
    ")\n",
    "data_parser = qut01.data.dataset_parser.DataParser(  # this will give us a easy-to-use parser for the dataset\n",
    "    dataset_path_or_object=dataset,\n",
    "    use_processed_data_cache=False,  # we will iterate over the entire dataset below, caching might go out of memory\n",
    ")\n",
    "potentially_annotated_statement_ids = data_parser.get_potentially_annotated_statement_ids()\n",
    "all_annot_sids = set([sid for annot_sids in potentially_annotated_statement_ids.values() for sid in annot_sids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1a38aa8396771",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_counts = []  # overall\n",
    "relevant_sentence_counts = {}  # per annot type\n",
    "irrelevant_sentence_counts = {}  # per annot type\n",
    "word_counts = []  # overall\n",
    "for target_sid in tqdm.tqdm(all_annot_sids, desc=\"parsing all annotated statements\"):\n",
    "    target_idx = data_parser.statement_ids.index(target_sid)\n",
    "    statement_processed_data = data_parser.get_processed_data(target_idx)\n",
    "    sentence_counts.append(len(statement_processed_data.sentences))\n",
    "    for sentence in statement_processed_data.sentences:\n",
    "        word_counts.append(len(sentence.split(\" \")))\n",
    "\n",
    "\n",
    "print(f\"\\ttotal sentence count: {sum(sentence_counts)}\")\n",
    "print(f\"\\ttotal word count: {sum(word_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92d8243e083285",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{min(sentence_counts)=}\")\n",
    "print(f\"{max(sentence_counts)=}\")\n",
    "sentence_counts = np.asarray(sentence_counts)\n",
    "mean_sentence_count = np.mean(sentence_counts)\n",
    "print(f\"{mean_sentence_count=}\")\n",
    "max_sentence_count = 600  # eliminate outliers\n",
    "filtered_sentence_counts = sentence_counts[sentence_counts <= max_sentence_count]\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(4.0, 4.0), dpi=300)\n",
    "ax.hist(filtered_sentence_counts, color=\"skyblue\", bins=30, edgecolor=\"black\")\n",
    "ax.axvline(mean_sentence_count, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {mean_sentence_count:.1f}\")\n",
    "ax.set_xlim([0, max_sentence_count])\n",
    "ax.set_ylim([0, 800])\n",
    "ax.set_xlabel(\"Number of sentences\", fontsize=12, weight=\"bold\")\n",
    "ax.set_ylabel(\"Number of statements\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"sentence_count_distrib.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f87bde902348c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{min(word_counts)=}\")\n",
    "print(f\"{max(word_counts)=}\")\n",
    "word_counts = np.asarray(word_counts)\n",
    "mean_word_count = np.mean(word_counts)\n",
    "print(f\"{mean_word_count=}\")\n",
    "max_sentence_count = 100  # eliminate outliers\n",
    "filtered_word_counts = word_counts[word_counts <= max_sentence_count]\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(4.0, 4.0), dpi=300)\n",
    "ax.hist(filtered_word_counts, color=\"#D8BFD8\", bins=30, edgecolor=\"black\")\n",
    "ax.axvline(mean_word_count, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Mean: {mean_word_count:.1f}\")\n",
    "ax.set_xlim([0, max_sentence_count])\n",
    "ax.set_ylim([0, 100000])\n",
    "ax.set_xlabel(\"Number of words\", fontsize=12, weight=\"bold\")\n",
    "ax.set_ylabel(\"Number of sentences\", fontsize=12, weight=\"bold\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"word_count_distrib.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
