{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f95b11c07b3986",
   "metadata": {},
   "source": [
    "# Statement DataModule Analysis\n",
    "\n",
    "This notebook analyzes the data loaded by the statement data module. For a more simple demo showing\n",
    "how to parse the statement dataset, see [this notebook](./data_parsing_demo.ipynb).\n",
    "\n",
    "This notebook was last updated on 2024-05-07 for framework v0.5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b09a65015e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import hydra\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import qut01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = qut01.utils.logging.setup_logging_for_analysis_script()\n",
    "data_config_name = \"statement_sampler.yaml\"\n",
    "logger.info(f\"initializing hydra and fetching data config for '{data_config_name}'...\")\n",
    "overrides = [\n",
    "    f\"data={data_config_name}\",\n",
    "    \"data.classif_setup=any\",\n",
    "    \"data.num_criteria=11\",\n",
    "    \"++data.tokenizer._target_=transformers.AutoTokenizer.from_pretrained\",\n",
    "    \"++data.tokenizer.pretrained_model_name_or_path=distilbert-base-uncased\",\n",
    "    \"utils.default_num_workers=0\",\n",
    "]\n",
    "config = qut01.utils.config.init_hydra_and_compose_config(overrides=overrides)\n",
    "logger.info(\"initialization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041003af0a8a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Instantiating datamodule: {config.data.datamodule._target_}\")  # noqa\n",
    "datamodule: pl.LightningDataModule = hydra.utils.instantiate(config.data.datamodule)\n",
    "assert isinstance(datamodule, pl.LightningDataModule), f\"unexpected type: {type(datamodule)}\"\n",
    "logger.info(\"running 'datamodule.prepare_data()'...\")\n",
    "datamodule.prepare_data()\n",
    "logger.info(\"running 'datamodule.setup()'...\")\n",
    "datamodule.setup(stage=\"fit\")\n",
    "target_subset_name = \"train\"\n",
    "logger.info(f\"fetching {target_subset_name} data loader...\")\n",
    "dataloader_getter = getattr(datamodule, f\"{target_subset_name}_dataloader\")\n",
    "dataloader = dataloader_getter()\n",
    "logger.info(f\"{target_subset_name} data loader ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1899128601594",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_texts = []\n",
    "sentence_tokens_padded = []\n",
    "sentence_counts = []\n",
    "sentence_relevance_arrays = []\n",
    "sentence_evidence_arrays = []\n",
    "sentence_statement_ids = []\n",
    "class_names = None\n",
    "\n",
    "for batch in tqdm.tqdm(dataloader, desc=\"parsing sentence text and label data\"):\n",
    "    if batch is None:\n",
    "        continue\n",
    "    sentence_texts.extend(batch[\"sentence_orig_text\"])\n",
    "    sentence_tokens_padded.extend([st for st in batch[\"sentence_token_ids\"].numpy()])\n",
    "    sentence_counts.append(len(batch[\"sentence_orig_text\"]))\n",
    "    sentence_relevance_arrays.append(\n",
    "        np.ma.array(\n",
    "            data=batch[\"relevance\"].numpy(),\n",
    "            mask=batch[\"relevance_dontcare_mask\"].numpy(),\n",
    "        )\n",
    "    )\n",
    "    sentence_evidence_arrays.append(\n",
    "        np.ma.array(\n",
    "            data=batch[\"evidence\"].numpy(),\n",
    "            mask=batch[\"evidence_dontcare_mask\"].numpy(),\n",
    "        )\n",
    "    )\n",
    "    sentence_statement_ids.extend(batch[\"statement_id\"])\n",
    "    if class_names is None:\n",
    "        class_names = batch[\"class_names\"]\n",
    "    else:\n",
    "        assert class_names == batch[\"class_names\"]\n",
    "\n",
    "padding_token_id = 0  # the un-padding of token sequences below assumes that padding id = 0\n",
    "sentence_tokens = []\n",
    "for tokens in sentence_tokens_padded:  # go through all token sequences to remove padding\n",
    "    pad_positions = np.where(tokens == padding_token_id)[0]\n",
    "    if pad_positions.size == 0:  # no padding used\n",
    "        sentence_tokens.append(tokens)  # use whole token array\n",
    "    else:  # there is some padding\n",
    "        sentence_tokens.append(tokens[: pad_positions[0]])  # keep slice up to padding\n",
    "sentence_relevance_arrays = np.ma.concatenate(sentence_relevance_arrays, axis=0)\n",
    "sentence_evidence_arrays = np.ma.concatenate(sentence_evidence_arrays, axis=0)\n",
    "statement_ids = set(sentence_statement_ids)\n",
    "tot_sentence_count = len(sentence_texts)\n",
    "tot_statement_count = len(statement_ids)\n",
    "logger.info(f\"parsed data for {tot_sentence_count} sentences across {tot_statement_count} statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f91fbb1f4cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 6])  # noqa\n",
    "ax.hist(sentence_counts, bins=50, color=\"blue\", edgecolor=\"black\")\n",
    "ax.set_title(\n",
    "    f\"Histogram of sentence counts in batches of {dataloader.batch_size} statements\"\n",
    "    f\"\\n(min={np.min(sentence_counts)}, mean={np.mean(sentence_counts):.1f}, \"\n",
    "    f\"std={np.std(sentence_counts):.1f}, max={np.max(sentence_counts)})\"\n",
    ")\n",
    "ax.set_xlabel(\"Sentence count\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.grid(axis=\"y\", alpha=0.75)\n",
    "ax.yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ff54cd8476042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_char_lengths = [len(s) for s in sentence_texts]\n",
    "sentence_token_lengths = [len(s) for s in sentence_tokens]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=[14, 12])  # noqa\n",
    "nbins = 80\n",
    "\n",
    "axs[0, 0].hist(sentence_char_lengths, bins=nbins, color=\"orange\", edgecolor=\"black\")\n",
    "axs[0, 0].set_xlabel(\"Sentence length (in chars)\")\n",
    "axs[0, 0].set_ylabel(\"Frequency\")\n",
    "axs[0, 0].grid(axis=\"y\", alpha=0.75)\n",
    "axs[0, 0].yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "\n",
    "axs[0, 1].hist(sentence_char_lengths, bins=nbins, color=\"orange\", edgecolor=\"black\", log=True)\n",
    "axs[0, 1].set_xlabel(\"Sentence length (in chars)\")\n",
    "axs[0, 1].set_ylabel(\"Frequency (log)\")\n",
    "axs[0, 1].grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "axs[1, 0].hist(sentence_token_lengths, bins=nbins, color=\"red\", edgecolor=\"black\")\n",
    "axs[1, 0].set_xlabel(\"Sentence length (in tokens)\")\n",
    "axs[1, 0].set_ylabel(\"Frequency\")\n",
    "axs[1, 0].grid(axis=\"y\", alpha=0.75)\n",
    "axs[1, 0].yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "\n",
    "axs[1, 1].hist(sentence_token_lengths, bins=nbins, color=\"red\", edgecolor=\"black\", log=True)\n",
    "axs[1, 1].set_xlabel(\"Sentence length (in tokens)\")\n",
    "axs[1, 1].set_ylabel(\"Frequency (log)\")\n",
    "axs[1, 1].grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Histogram of sentence lengths across {tot_statement_count} statements\"\n",
    "    f\"\\n(chars: min={np.min(sentence_char_lengths)}, mean={np.mean(sentence_char_lengths):.1f}, \"\n",
    "    f\"std={np.std(sentence_char_lengths):.1f}, max={np.max(sentence_char_lengths)})\"\n",
    "    f\"\\n(tokens: min={np.min(sentence_token_lengths)}, mean={np.mean(sentence_token_lengths):.1f}, \"\n",
    "    f\"std={np.std(sentence_token_lengths):.1f}, max={np.max(sentence_token_lengths)})\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfaad58634f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sentence_relevance_arrays.ndim == 2 and sentence_evidence_arrays.ndim == 2\n",
    "assert len(sentence_relevance_arrays) == len(sentence_evidence_arrays)\n",
    "assert sentence_relevance_arrays.shape[1] == len(class_names)\n",
    "assert sentence_evidence_arrays.shape[1] == len(class_names)\n",
    "assert sentence_relevance_arrays.count() > 0 and sentence_evidence_arrays.count() > 0\n",
    "valid_relevance_labels = sentence_relevance_arrays.count()\n",
    "valid_evidence_labels = sentence_evidence_arrays.count()\n",
    "valid_relevance_label_ratio = valid_relevance_labels / sentence_relevance_arrays.size\n",
    "valid_evidence_label_ratio = valid_evidence_labels / sentence_evidence_arrays.size\n",
    "assert tuple(np.unique(sentence_relevance_arrays.compressed())) == (0, 1)  # expect hard binary labels\n",
    "assert tuple(np.unique(sentence_evidence_arrays.compressed())) == (0, 1)  # expect hard binary labels\n",
    "# by definition, all sentences that are \"irrelevant\" should have dontcare for evidence\n",
    "irrelevant_evidence_flags = sentence_evidence_arrays[sentence_relevance_arrays.mask].flatten()\n",
    "assert irrelevant_evidence_flags.count() == 0\n",
    "positive_relevance_labels = np.ma.sum(sentence_relevance_arrays)\n",
    "positive_evidence_labels = np.ma.sum(sentence_evidence_arrays)\n",
    "positive_relevance_label_ratio = positive_relevance_labels / sentence_relevance_arrays.count()\n",
    "positive_evidence_label_ratio = positive_evidence_labels / sentence_evidence_arrays.count()\n",
    "print(f\"total_labels={sentence_relevance_arrays.size}\")\n",
    "print(f\"{valid_relevance_labels=}  ({valid_relevance_label_ratio:.1%})\")\n",
    "print(f\"{valid_evidence_labels=}  ({valid_evidence_label_ratio:.1%})\")\n",
    "print(f\"{positive_relevance_labels=}  ({positive_relevance_label_ratio:.1%})\")\n",
    "print(f\"{positive_evidence_labels=}  ({positive_evidence_label_ratio:.1%})\")\n",
    "class_index = np.arange(len(class_names))\n",
    "class_pos_relevance_labels = np.ma.sum(sentence_relevance_arrays, axis=0)\n",
    "class_pos_relevance_ratios = class_pos_relevance_labels / np.ma.count(sentence_relevance_arrays, axis=0)\n",
    "class_pos_evidence_labels = np.ma.sum(sentence_evidence_arrays, axis=0)\n",
    "class_pos_evidence_ratios = class_pos_evidence_labels / np.ma.count(sentence_evidence_arrays, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96413192095ed25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=[14, 6])  # noqa\n",
    "bar_width = 0.35\n",
    "\n",
    "axs[0].bar(class_index, class_pos_relevance_ratios, bar_width, color=\"blue\", label=\"Positive\")\n",
    "bars = axs[0].bar(class_index + bar_width, 1 - class_pos_relevance_ratios, bar_width, color=\"red\", label=\"Negative\")\n",
    "axs[0].set_xticks(class_index + bar_width / 2)\n",
    "axs[0].set_xticklabels(class_names, rotation=45)\n",
    "axs[0].set_ylabel(\"Relevance (percentage)\")\n",
    "axs[0].grid(axis=\"y\", alpha=0.75)\n",
    "for bar_idx, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    axs[0].text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height / 2,\n",
    "        f\"{1 - class_pos_relevance_ratios[bar_idx]:.1%}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        rotation=90,\n",
    "    )\n",
    "\n",
    "bars = axs[1].bar(class_index, class_pos_evidence_ratios, bar_width, color=\"blue\", label=\"Positive\")\n",
    "axs[1].bar(class_index + bar_width, 1 - class_pos_evidence_ratios, bar_width, color=\"red\", label=\"Negative\")\n",
    "axs[1].set_xticks(class_index + bar_width / 2)\n",
    "axs[1].set_xticklabels(class_names, rotation=45)\n",
    "axs[1].set_ylabel(\"Evidence (percentage)\")\n",
    "axs[1].grid(axis=\"y\", alpha=0.75)\n",
    "for bar_idx, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    axs[1].text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height / 2,\n",
    "        f\"{class_pos_evidence_ratios[bar_idx]:.1%}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        rotation=90,\n",
    "    )\n",
    "\n",
    "handles, labels = axs[1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"lower center\")\n",
    "fig.suptitle(f\"Distribution of positive/negative labels across {tot_sentence_count} sentences\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
