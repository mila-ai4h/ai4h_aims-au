{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749b2db7f3f19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import qut01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "qut01.utils.logging.setup_logging_for_analysis_script()\n",
    "dataset_path = qut01.data.dataset_parser.get_default_deeplake_dataset_path()\n",
    "\n",
    "dataset = qut01.data.dataset_parser.get_deeplake_dataset(  # this will load the deeplake dataset itself\n",
    "    dataset_path=dataset_path,\n",
    "    checkout_branch=qut01.data.dataset_parser.dataset_validated_branch_name,  # to load all annotations\n",
    "    # in order to load only annotated provided by hired workers, used the `dataset_annotated_branch_name` branch\n",
    ")\n",
    "data_parser = qut01.data.dataset_parser.DataParser(  # this will give us a easy-to-use parser for the dataset\n",
    "    dataset_path_or_object=dataset,\n",
    "    add_processed_data_to_batch=True,\n",
    "    use_processed_data_cache=False,  # we will iterate over the entire dataset below, caching might go out of memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ddd47a72a7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "potentially_annotated_statement_ids = data_parser.get_potentially_annotated_statement_ids()\n",
    "potentially_annotated_statement_counts = {k: len(np.unique(v)) for k, v in potentially_annotated_statement_ids.items()}\n",
    "print(f\"\\npotentially annotated statement counts across annot groups:\\n\\t{potentially_annotated_statement_counts}\")\n",
    "all_annot_sids = set([sid for annot_sids in potentially_annotated_statement_ids.values() for sid in annot_sids])\n",
    "\n",
    "print(f\"\\ndataset contains {len(data_parser)} statements (and {len(all_annot_sids)} with potential annotations)\")\n",
    "\n",
    "statement_idxs = sorted([data_parser.statement_ids.index(sid) for sid in all_annot_sids])\n",
    "print(f\"will extract metadata from {len(statement_idxs)} statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fac0a43a3b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_sentence_counter(statement_data):\n",
    "    # note: if the statement is not annotated, we return nothing for that criteria\n",
    "    # (means we can avoid aggregating unannotated statements in stats)\n",
    "    output = {}\n",
    "    for cname in qut01.data.classif_utils.ANNOT_CLASS_NAMES:\n",
    "        if not statement_data[\"processed_data\"].annotation_counts.get(cname, 0):\n",
    "            continue\n",
    "        tot_annot_sentence_count = 0\n",
    "        for annot_counts in statement_data[\"processed_data\"].sentence_annotation_counts:\n",
    "            if annot_counts.get(cname, 0):\n",
    "                tot_annot_sentence_count += 1\n",
    "        output[cname] = tot_annot_sentence_count\n",
    "    return output\n",
    "\n",
    "\n",
    "fields_to_extract = {\n",
    "    \"text_lengths\": lambda x: [len(x[\"fitz/text\"].item())],\n",
    "    \"word_counts\": lambda x: [x[\"metadata/WordCount\"].item()],\n",
    "    \"sentence_counts\": lambda x: [len(x[\"processed_data\"].sentences)],\n",
    "    \"annual_revenues\": lambda x: [x[\"metadata/AnnualRevenue\"].item()],\n",
    "    \"countries\": lambda x: x[\"metadata/Countries\"].tolist(),\n",
    "    \"entities\": lambda x: x[\"metadata/Entities\"].tolist(),\n",
    "    \"industry_sectors\": lambda x: x[\"metadata/IndustrySectors\"].tolist(),\n",
    "    \"page_counts\": lambda x: [x[\"metadata/PageCount\"].item()],\n",
    "    \"timestamps\": lambda x: [x[\"metadata/PeriodEnd\"].item()],\n",
    "    \"trademarks\": lambda x: x[\"metadata/Trademarks\"].tolist(),\n",
    "    \"relevant_sentence_counts\": lambda x: [relevant_sentence_counter(x)],\n",
    "}\n",
    "\n",
    "extracted_data = {key: [] for key in fields_to_extract}\n",
    "\n",
    "for sidx in tqdm.tqdm(statement_idxs, \"extracting metadata\"):\n",
    "    statement_data = data_parser[sidx]\n",
    "    for field, getter in fields_to_extract.items():\n",
    "        extracted_data[field].extend(getter(statement_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1cccf22065a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_count = len(set([s.strip() for strs in extracted_data[\"industry_sectors\"] for s in strs.split(\"\\n\")]))\n",
    "print(f\"industrial sectors: {sector_count}\")\n",
    "trademarks = len(set([s.strip() for strs in extracted_data[\"trademarks\"] for s in strs.split(\",\")]))\n",
    "print(f\"trademarks: {trademarks}\")\n",
    "entities = len(set([s.strip() for entities in extracted_data[\"entities\"] for s in entities.split(\",\")]))\n",
    "print(f\"entities: {entities}\")\n",
    "\n",
    "avg_word_count = np.mean(extracted_data[\"word_counts\"])\n",
    "avg_sentence_count = np.mean(extracted_data[\"sentence_counts\"])\n",
    "avg_page_count = np.mean(extracted_data[\"page_counts\"])\n",
    "print(f\"avg word count: {avg_word_count:.2f}\")\n",
    "print(f\"avg sentence count: {avg_sentence_count:.2f}\")\n",
    "print(f\"avg page count: {avg_page_count:.2f}\")\n",
    "tot_word_count = sum(extracted_data[\"word_counts\"])\n",
    "tot_sentence_count = sum(extracted_data[\"sentence_counts\"])\n",
    "tot_page_count = sum(extracted_data[\"page_counts\"])\n",
    "print(f\"total word count: {tot_word_count}\")\n",
    "print(f\"total sentence count: {tot_sentence_count}\")\n",
    "print(f\"total page count: {tot_page_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab80c86043ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the pie chart for page counts\n",
    "bins = [0, 5, 10, 15, 30, float(\"inf\")]\n",
    "bin_labels = [\"1-5\", \"5-10\", \"10-15\", \"15-30\", \"30+\"]\n",
    "bin_counts = [0] * (len(bins) - 1)\n",
    "# bin_colors = [\"#1f77b4\", \"#9467bd\", \"#ff7f0e\", \"#d62728\", \"#ff0000\"]\n",
    "page_counts = copy.deepcopy(extracted_data[\"page_counts\"])\n",
    "for count in page_counts:\n",
    "    for i in range(len(bins) - 1):\n",
    "        if bins[i] < count <= bins[i + 1]:\n",
    "            bin_counts[i] += 1\n",
    "            break\n",
    "plt.figure(figsize=(4.5, 4.5))\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    bin_counts,\n",
    "    labels=bin_labels,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    "    # colors=bin_colors,\n",
    "    wedgeprops={\"edgecolor\": \"black\", \"linewidth\": 1.25, \"antialiased\": True},\n",
    "    textprops={\"fontsize\": 14, \"weight\": \"bold\"},\n",
    ")\n",
    "for text in texts:\n",
    "    text.set_color(\"black\")\n",
    "    text.set_fontsize(12)\n",
    "    text.set_fontweight(\"bold\")\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color(\"white\")\n",
    "    autotext.set_fontsize(12)\n",
    "    autotext.set_fontweight(\"bold\")\n",
    "plt.savefig(\"page_count.pdf\", format=\"pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce7a43aca9bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_sentence_counts = {cname: [] for cname in qut01.data.classif_utils.ANNOT_CLASS_NAMES}\n",
    "irrelevant_sentence_counts = {cname: [] for cname in qut01.data.classif_utils.ANNOT_CLASS_NAMES}\n",
    "relevant_sentence_ratios = {cname: [] for cname in qut01.data.classif_utils.ANNOT_CLASS_NAMES}\n",
    "\n",
    "for sen_count, annot_counts in zip(extracted_data[\"sentence_counts\"], extracted_data[\"relevant_sentence_counts\"]):\n",
    "    for cname in annot_counts:\n",
    "        if sen_count > 0:\n",
    "            assert sen_count >= annot_counts[cname]\n",
    "            relevant_sentence_counts[cname].append(annot_counts[cname])\n",
    "            irrelevant_sentence_counts[cname].append(sen_count - annot_counts[cname])\n",
    "            relevant_sentence_ratios[cname].append(annot_counts[cname] / sen_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0a31f512a88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.0), dpi=300)\n",
    "relevant_sentence_ratios = {k: relevant_sentence_ratios[k] for k in sorted(relevant_sentence_ratios)}\n",
    "labels = list(relevant_sentence_ratios.keys())\n",
    "distributions = list(relevant_sentence_ratios.values())\n",
    "palette = sns.color_palette(\"husl\", len(relevant_sentence_ratios.keys()))\n",
    "bxplot = ax.boxplot(\n",
    "    distributions,\n",
    "    labels=labels,\n",
    "    showfliers=False,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(linewidth=1, edgecolor=\"black\", facecolor=\"w\"),\n",
    "    whiskerprops=dict(linewidth=1, color=\"black\"),\n",
    "    medianprops=dict(linewidth=1, color=\"black\"),\n",
    ")\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_rotation(30)\n",
    "    label.set_horizontalalignment(\"right\")\n",
    "    label.set_fontsize(11)\n",
    "    label.set_weight(\"bold\")\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontsize(11)\n",
    "for patch, color in zip(bxplot[\"boxes\"], palette):\n",
    "    patch.set_facecolor(color)\n",
    "ax.set_ylabel(\"Relevant sentence ratio\", fontsize=12, weight=\"bold\")\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"relevant_ratios.pdf\", dpi=300, format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
